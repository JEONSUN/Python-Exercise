{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 카페 크롤링\n",
    "\n",
    "- 아이오닉5 멤버스의 Q&A 게시판 크롤링\n",
    "\n",
    "\n",
    "### 댓글 크롤링은 추후 추가예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "# 크롬 웹브라우저 실행\n",
    "path = \"chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈창 만들기 (로그인 수동으로 해주기) : sendkeys 써도 되지만 그냥 직접 해줌\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "\n",
    "driver.get('https://cafe.naver.com/cafeclip')\n",
    "time.sleep(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자유게시판 리스트 50개 기준\n",
    "df = pd.DataFrame()\n",
    "content_list = []\n",
    "for i in range(1): #스크래핑 할 페이지수 #강제# 중간에 끊겼을때 해당 페이수보다 -1 한 값을 입력하고 주석 제거 #i = i + 15 #강제# \n",
    "    pg = str(i+1) \n",
    "    addr = 'https://cafe.naver.com/ArticleList.nhn?search.clubid=16598058&search.menuid=1110&userDisplay=5&search.boardtype=L&search.specialmenutype=&search.totalCount=501&search.page='+pg \n",
    "    driver.get(addr) \n",
    "    driver.switch_to.frame('cafe_main') \n",
    "    html = driver.page_source \n",
    "    soup = BeautifulSoup(html, 'html.parser') \n",
    "    a_num_list = soup.findAll(\"div\",{\"class\":\"inner_number\"}) \n",
    "    a_title_list = soup.findAll(\"a\",{\"class\":\"article\"})\n",
    "    a_writer_list = soup.findAll(\"a\",{\"class\":\"m-tcol-c\"}) \n",
    "    a_regdate_list = soup.findAll(\"td\",{\"class\":\"td_date\"}) \n",
    "    total_list = [] \n",
    "    article_link_list = []\n",
    "    url_list=[]\n",
    "#글 링크 \n",
    "    if i == 0: \n",
    "        for a, b, c, d in zip(a_num_list, a_title_list[7:], a_writer_list[7:], a_regdate_list[7:]): # URL, 제목, ID, 날짜 추출\n",
    "            list = [] \n",
    "            list.append(a.text) \n",
    "            list.append(b.text.strip()) \n",
    "            list.append(c.text) \n",
    "            list.append(d.text) \n",
    "            total_list.append(list) \n",
    "            article_link_list.append(\"https://cafe.naver.com/ArticleRead.nhn?clubid=16598058&page=\" + pg + \"&userDisplay=5&menuid=1110&boardtype=L&articleid=\" + a.text + \"&referrerAllArticles=false\") \n",
    "    else: \n",
    "        for a, b, c, d in zip(a_num_list, a_title_list, a_writer_list, a_regdate_list): \n",
    "            list = [] \n",
    "            list.append(a.text) \n",
    "            list.append(b.text.strip()) \n",
    "            list.append(c.text) \n",
    "            list.append(d.text) \n",
    "            total_list.append(list) \n",
    "            article_link_list.append(\"https://cafe.naver.com/ArticleRead.nhn?clubid=16598058&page=\" + pg + \"&userDisplay=5&menuid=1110&boardtype=L&articleid=\" + a.text + \"&referrerAllArticles=false\") \n",
    "    # 글 스크랩핑 \n",
    "    for x in total_list: \n",
    "        adrs = \"https://cafe.naver.com/ArticleRead.nhn?clubid=16598058&page=\" + str(pg) + \"&userDisplay=5&menuid=1110&boardtype=L&articleid=\" + x[0] +\"&referrerAllArticles=false\" \n",
    "        url_list.append(adrs)\n",
    "        print(adrs)\n",
    "        \n",
    "        driver.get(adrs) \n",
    "        time.sleep(2) \n",
    "        driver.switch_to.frame('cafe_main') \n",
    "        html = driver.page_source \n",
    "        soup = BeautifulSoup(html, 'html.parser') \n",
    "        list = soup.find_all(\"div\", {\"class\":\"article_viewer\"}) \n",
    "        for xx in list: \n",
    "            content_list = []\n",
    "            cont = '' \n",
    "            cont += re.sub('[^A-Za-z0-9가-힣\\s,.,?,!]', \"\", xx.text.strip()).replace('\\n','')\n",
    "            content_list.append(cont)\n",
    "            mydict = {'content' : content_list}\n",
    "            df = df.append(mydict,ignore_index = True)\n",
    "    # 리스트 변수 초기화 \n",
    "    a_num_list = [] \n",
    "    a_title_list = [] \n",
    "    a_writer_list = [] \n",
    "    a_regdate_list = []\n",
    "    print(\"############################################# \" + pg + \" 페이지 완료 #############################################\")\n",
    "\n",
    "#driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
