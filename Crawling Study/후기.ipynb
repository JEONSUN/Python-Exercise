{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20d89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from urllib.parse import quote\n",
    "# 크롬 웹브라우저 실행\n",
    "path = \"chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076920fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [01:03<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url 수집 끝, 해당 url 데이터 크롤링\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 203/203 [13:16<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크롤링도 끝\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "# 빈창 만들기\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    " \n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "url_list = []\n",
    "title=[]\n",
    "name=[]\n",
    "day=[]\n",
    "content_list = \"\"\n",
    "text = \"전기차 장단점\"\n",
    "\n",
    " \n",
    "\n",
    "for i in tqdm(range(1, math.ceil(207/7))):  # 1~2페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.naver?pageNo='+ str(i) +\\\n",
    "    '&rangeType=PERIOD&orderBy=sim&startDate=2016-01-01&endDate=2016-12-31&keyword='+text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    for j in range(1, 8): # 각 블로그 주소 저장(8개로!)\n",
    "        url_titles = driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner'.format(j))\n",
    "        url_title = url_titles.get_attribute('href')\n",
    "        url_list.append(url_title)\n",
    "        titles=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner > strong > span'.format(j)).text\n",
    "        title.append(titles)\n",
    "        names=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > a > em'.format(j)).text\n",
    "        name.append(names)\n",
    "        days=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > span.date'.format(j)).text\n",
    "        day.append(days)\n",
    "\n",
    "                    \n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")\n",
    "result=[]\n",
    "\n",
    " \n",
    "for url in tqdm(url_list): # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    overlays = \".se-component.se-text.se-l-default\" # 내용 크롤링\n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    driver.implicitly_wait(1)\n",
    "\n",
    "\n",
    "    for content in contents:\n",
    "        content_list = content_list+content.text # content_list 라는 값에 + 하면서 점점 누적\n",
    "\n",
    "    \n",
    "    result.append(content_list)\n",
    "    content_list=''    \n",
    "\n",
    "## result라는 최종 데이터 프레임 생성\n",
    "result=pd.DataFrame(result, columns = ['리뷰']) #리뷰로 먼저 만들고\n",
    "result['url']=url_list # url 새로운 열로 추가\n",
    "result['title']=title\n",
    "result['name']=name\n",
    "result['day']=day\n",
    "result = result[['name','day','url','title','리뷰']]\n",
    "result.to_excel('전기차 장단점(16년).xlsx')\n",
    "print(\"크롤링도 끝\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e6082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [01:50<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url 수집 끝, 해당 url 데이터 크롤링\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 350/350 [32:44<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크롤링도 끝\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "# 빈창 만들기\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    " \n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "url_list = []\n",
    "title=[]\n",
    "name=[]\n",
    "day=[]\n",
    "content_list = \"\"\n",
    "text = \"전기차 장단점\"\n",
    "\n",
    " \n",
    "\n",
    "for i in tqdm(range(1, math.ceil(355/7))):  # 1~2페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.naver?pageNo='+ str(i) +\\\n",
    "    '&rangeType=PERIOD&orderBy=sim&startDate=2017-01-01&endDate=2017-12-31&keyword='+text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    for j in range(1, 8): # 각 블로그 주소 저장(8개로!)\n",
    "        url_titles = driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner'.format(j))\n",
    "        url_title = url_titles.get_attribute('href')\n",
    "        url_list.append(url_title)\n",
    "        titles=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner > strong > span'.format(j)).text\n",
    "        title.append(titles)\n",
    "        names=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > a > em'.format(j)).text\n",
    "        name.append(names)\n",
    "        days=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > span.date'.format(j)).text\n",
    "        day.append(days)\n",
    "\n",
    "                    \n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")\n",
    "result=[]\n",
    "\n",
    " \n",
    "for url in tqdm(url_list): # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    overlays = \".se-component.se-text.se-l-default\" # 내용 크롤링\n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    driver.implicitly_wait(1)\n",
    "\n",
    "\n",
    "    for content in contents:\n",
    "        content_list = content_list+content.text # content_list 라는 값에 + 하면서 점점 누적\n",
    "\n",
    "    \n",
    "    result.append(content_list)\n",
    "    content_list=''    \n",
    "\n",
    "## result라는 최종 데이터 프레임 생성\n",
    "result=pd.DataFrame(result, columns = ['리뷰']) #리뷰로 먼저 만들고\n",
    "result['url']=url_list # url 새로운 열로 추가\n",
    "result['title']=title\n",
    "result['name']=name\n",
    "result['day']=day\n",
    "result = result[['name','day','url','title','리뷰']]\n",
    "result.to_excel('전기차 장단점(17년).xlsx')\n",
    "print(\"크롤링도 끝\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "# 빈창 만들기\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    " \n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "url_list = []\n",
    "title=[]\n",
    "name=[]\n",
    "day=[]\n",
    "content_list = \"\"\n",
    "text = \"전기차 장단점\"\n",
    "\n",
    " \n",
    "\n",
    "for i in tqdm(range(1, math.ceil(603/7))):  # 1~2페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.naver?pageNo='+ str(i) +\\\n",
    "    '&rangeType=PERIOD&orderBy=sim&startDate=2018-01-01&endDate=2018-12-31&keyword='+text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    for j in range(1, 8): # 각 블로그 주소 저장(8개로!)\n",
    "        url_titles = driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner'.format(j))\n",
    "        url_title = url_titles.get_attribute('href')\n",
    "        url_list.append(url_title)\n",
    "        titles=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner > strong > span'.format(j)).text\n",
    "        title.append(titles)\n",
    "        names=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > a > em'.format(j)).text\n",
    "        name.append(names)\n",
    "        days=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > span.date'.format(j)).text\n",
    "        day.append(days)\n",
    "\n",
    "                    \n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")\n",
    "result=[]\n",
    "\n",
    " \n",
    "for url in tqdm(url_list): # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    overlays = \".se-component.se-text.se-l-default\" # 내용 크롤링\n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    driver.implicitly_wait(1)\n",
    "\n",
    "\n",
    "    for content in contents:\n",
    "        content_list = content_list+content.text # content_list 라는 값에 + 하면서 점점 누적\n",
    "\n",
    "    \n",
    "    result.append(content_list)\n",
    "    content_list=''    \n",
    "\n",
    "## result라는 최종 데이터 프레임 생성\n",
    "result=pd.DataFrame(result, columns = ['리뷰']) #리뷰로 먼저 만들고\n",
    "result['url']=url_list # url 새로운 열로 추가\n",
    "result['title']=title\n",
    "result['name']=name\n",
    "result['day']=day\n",
    "result = result[['name','day','url','title','리뷰']]\n",
    "result.to_excel('전기차 장단점(18년).xlsx')\n",
    "print(\"크롤링도 끝\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "# 빈창 만들기\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    " \n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "url_list = []\n",
    "title=[]\n",
    "name=[]\n",
    "day=[]\n",
    "content_list = \"\"\n",
    "text = \"전기차 장단점\"\n",
    "\n",
    " \n",
    "\n",
    "for i in tqdm(range(1, math.ceil(956/7))):  # 1~2페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.naver?pageNo='+ str(i) +\\\n",
    "    '&rangeType=PERIOD&orderBy=sim&startDate=2019-01-01&endDate=2019-12-31&keyword='+text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    for j in range(1, 8): # 각 블로그 주소 저장(8개로!)\n",
    "        url_titles = driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner'.format(j))\n",
    "        url_title = url_titles.get_attribute('href')\n",
    "        url_list.append(url_title)\n",
    "        titles=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner > strong > span'.format(j)).text\n",
    "        title.append(titles)\n",
    "        names=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > a > em'.format(j)).text\n",
    "        name.append(names)\n",
    "        days=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > span.date'.format(j)).text\n",
    "        day.append(days)\n",
    "\n",
    "                    \n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")\n",
    "result=[]\n",
    "\n",
    " \n",
    "for url in tqdm(url_list): # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    overlays = \".se-component.se-text.se-l-default\" # 내용 크롤링\n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    driver.implicitly_wait(1)\n",
    "\n",
    "\n",
    "    for content in contents:\n",
    "        content_list = content_list+content.text # content_list 라는 값에 + 하면서 점점 누적\n",
    "\n",
    "    \n",
    "    result.append(content_list)\n",
    "    content_list=''    \n",
    "\n",
    "## result라는 최종 데이터 프레임 생성\n",
    "result=pd.DataFrame(result, columns = ['리뷰']) #리뷰로 먼저 만들고\n",
    "result['url']=url_list # url 새로운 열로 추가\n",
    "result['title']=title\n",
    "result['name']=name\n",
    "result['day']=day\n",
    "result = result[['name','day','url','title','리뷰']]\n",
    "result.to_excel('전기차 장단점(19년).xlsx')\n",
    "print(\"크롤링도 끝\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7874c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "# 빈창 만들기\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    " \n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "url_list = []\n",
    "title=[]\n",
    "name=[]\n",
    "day=[]\n",
    "content_list = \"\"\n",
    "text = \"전기차 장단점\"\n",
    "\n",
    " \n",
    "\n",
    "for i in tqdm(range(1, math.ceil(1289/7))):  # 1~2페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.naver?pageNo='+str(i)+\\\n",
    "    '&rangeType=PERIOD&orderBy=sim&startDate=2020-01-01&endDate=2020-12-31&keyword='+text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    for j in range(1, 8): # 각 블로그 주소 저장(8개로!)\n",
    "        url_titles = driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner'.format(j))\n",
    "        url_title = url_titles.get_attribute('href')\n",
    "        url_list.append(url_title)\n",
    "        titles=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner > strong > span'.format(j)).text\n",
    "        title.append(titles)\n",
    "        names=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > a > em'.format(j)).text\n",
    "        name.append(names)\n",
    "        days=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > span.date'.format(j)).text\n",
    "        day.append(days)\n",
    "\n",
    "                    \n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")\n",
    "result=[]\n",
    "\n",
    " \n",
    "for url in tqdm(url_list): # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    overlays = \".se-component.se-text.se-l-default\" # 내용 크롤링\n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    driver.implicitly_wait(1)\n",
    "\n",
    "\n",
    "    for content in contents:\n",
    "        content_list = content_list+content.text # content_list 라는 값에 + 하면서 점점 누적\n",
    "\n",
    "    \n",
    "    result.append(content_list)\n",
    "    content_list=''    \n",
    "\n",
    "## result라는 최종 데이터 프레임 생성\n",
    "result=pd.DataFrame(result, columns = ['리뷰']) #리뷰로 먼저 만들고\n",
    "result['url']=url_list # url 새로운 열로 추가\n",
    "result['title']=title\n",
    "result['name']=name\n",
    "result['day']=day\n",
    "result = result[['name','day','url','title','리뷰']]\n",
    "result.to_excel('전기차 장단점(20년).xlsx')\n",
    "print(\"크롤링도 끝\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "# 빈창 만들기\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    " \n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "url_list = []\n",
    "title=[]\n",
    "name=[]\n",
    "day=[]\n",
    "content_list = \"\"\n",
    "text = \"전기차 장단점\"\n",
    "\n",
    " \n",
    "\n",
    "for i in tqdm(range(1, math.ceil(1498/7))):  # 1~2페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.naver?pageNo='+ str(i) +\\\n",
    "    '&rangeType=PERIOD&orderBy=sim&startDate=2021-01-01&endDate=2021-08-04&keyword=' + text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    for j in range(1, 8): # 각 블로그 주소 저장(8개로!)\n",
    "        url_titles = driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner'.format(j))\n",
    "        url_title = url_titles.get_attribute('href')\n",
    "        url_list.append(url_title)\n",
    "        titles=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner > strong > span'.format(j)).text\n",
    "        title.append(titles)\n",
    "        names=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > a > em'.format(j)).text\n",
    "        name.append(names)\n",
    "        days=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > span.date'.format(j)).text\n",
    "        day.append(days)\n",
    "\n",
    "                    \n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")\n",
    "result=[]\n",
    "\n",
    " \n",
    "for url in tqdm(url_list): # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    overlays = \".se-component.se-text.se-l-default\" # 내용 크롤링\n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    driver.implicitly_wait(1)\n",
    "\n",
    "\n",
    "    for content in contents:\n",
    "        content_list = content_list+content.text # content_list 라는 값에 + 하면서 점점 누적\n",
    "\n",
    "    \n",
    "    result.append(content_list)\n",
    "    content_list=''    \n",
    "\n",
    "## result라는 최종 데이터 프레임 생성\n",
    "result=pd.DataFrame(result, columns = ['리뷰']) #리뷰로 먼저 만들고\n",
    "result['url']=url_list # url 새로운 열로 추가\n",
    "result['title']=title\n",
    "result['name']=name\n",
    "result['day']=day\n",
    "result = result[['name','day','url','title','리뷰']]\n",
    "result.to_excel('전기차 장단점(21년).xlsx')\n",
    "print(\"크롤링도 끝\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "# 빈창 만들기\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "url_list = []\n",
    "title=[]\n",
    "name=[]\n",
    "day=[]\n",
    "content_list = \"\"\n",
    "text = \"전기차 후기\"\n",
    "\n",
    "for i in tqdm(range(1, math.ceil(1106/7))):  # 1~2페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.naver?pageNo='+ str(i) +\\\n",
    "    '&rangeType=PERIOD&orderBy=sim&startDate=2016-01-01&endDate=2016-12-31&keyword=' + text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    " \n",
    "    for j in range(1, 8): # 각 블로그 주소 저장(8개로!)\n",
    "        url_titles = driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner'.format(j))\n",
    "        url_title = url_titles.get_attribute('href')\n",
    "        url_list.append(url_title)\n",
    "\n",
    "        titles=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner > strong > span'.format(j)).text\n",
    "        title.append(titles)\n",
    "        \n",
    "        names=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > a > em'.format(j)).text\n",
    "        name.append(names)\n",
    "\n",
    "        days=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > span.date'.format(j)).text\n",
    "        day.append(days)\n",
    "                       \n",
    "        \n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")\n",
    "\n",
    "result=[]\n",
    "\n",
    "for url in tqdm(url_list): # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    " \n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    overlays = \".se-component.se-text.se-l-default\" # 내용 크롤링\n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    driver.implicitly_wait(1)\n",
    " \n",
    "    for content in contents:\n",
    "        content_list = content_list+content.text # content_list 라는 값에 + 하면서 점점 누적\n",
    "    \n",
    "    result.append(content_list)\n",
    "    content_list=''    \n",
    "\n",
    "    \n",
    "## result라는 최종 데이터 프레임 생성\n",
    "result=pd.DataFrame(result, columns = ['리뷰']) #리뷰로 먼저 만들고\n",
    "result['url']=url_list # url 새로운 열로 추가\n",
    "result['title']=title\n",
    "result['name']=name\n",
    "result['day']=day\n",
    "result = result[['name','day','url','title','리뷰']]\n",
    "result.to_excel('전기차 후기(16년).xlsx')\n",
    "\n",
    "print(\"크롤링도 끝\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "# 빈창 만들기\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "url_list = []\n",
    "title=[]\n",
    "name=[]\n",
    "day=[]\n",
    "content_list = \"\"\n",
    "text = \"전기차 후기\"\n",
    "\n",
    "for i in tqdm(range(1, math.ceil(2595/7))):  # 1~2페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.naver?pageNo='+ str(i) +\\\n",
    "    '&rangeType=PERIOD&orderBy=sim&startDate=2017-01-01&endDate=2017-12-31&keyword=' + text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    " \n",
    "    for j in range(1, 8): # 각 블로그 주소 저장(8개로!)\n",
    "        url_titles = driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner'.format(j))\n",
    "        url_title = url_titles.get_attribute('href')\n",
    "        url_list.append(url_title)\n",
    "\n",
    "        titles=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner > strong > span'.format(j)).text\n",
    "        title.append(titles)\n",
    "        \n",
    "        names=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > a > em'.format(j)).text\n",
    "        name.append(names)\n",
    "\n",
    "        days=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > span.date'.format(j)).text\n",
    "        day.append(days)\n",
    "                       \n",
    "        \n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")\n",
    "\n",
    "result=[]\n",
    "\n",
    "for url in tqdm(url_list): # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    " \n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    overlays = \".se-component.se-text.se-l-default\" # 내용 크롤링\n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    driver.implicitly_wait(1)\n",
    " \n",
    "    for content in contents:\n",
    "        content_list = content_list+content.text # content_list 라는 값에 + 하면서 점점 누적\n",
    "    \n",
    "    result.append(content_list)\n",
    "    content_list=''    \n",
    "\n",
    "    \n",
    "## result라는 최종 데이터 프레임 생성\n",
    "result=pd.DataFrame(result, columns = ['리뷰']) #리뷰로 먼저 만들고\n",
    "result['url']=url_list # url 새로운 열로 추가\n",
    "result['title']=title\n",
    "result['name']=name\n",
    "result['day']=day\n",
    "result = result[['name','day','url','title','리뷰']]\n",
    "result.to_excel('전기차 후기(17년).xlsx')\n",
    "\n",
    "print(\"크롤링도 끝\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444c852e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-6f95d215d506>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-6f95d215d506>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    for i in tqdm(range(1, 572):  # 1~2페이지까지의 블로그 내용을 읽어옴\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "# 빈창 만들기\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options = options)\n",
    "url_list = []\n",
    "title=[]\n",
    "name=[]\n",
    "day=[]\n",
    "content_list = \"\"\n",
    "text = \"전기차 후기\"\n",
    "\n",
    "for i in tqdm(range(1, 572)):  # 1~2페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.naver?pageNo='+ str(i) +\\\n",
    "    '&rangeType=PERIOD&orderBy=sim&startDate=2018-01-01&endDate=2018-12-31&keyword=' + text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    " \n",
    "    for j in range(1, 8): # 각 블로그 주소 저장(8개로!)\n",
    "        url_titles = driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner'.format(j))\n",
    "        url_title = url_titles.get_attribute('href')\n",
    "        url_list.append(url_title)\n",
    "\n",
    "        titles=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.desc > a.desc_inner > strong > span'.format(j)).text\n",
    "        title.append(titles)\n",
    "        \n",
    "        names=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > a > em'.format(j)).text\n",
    "        name.append(names)\n",
    "\n",
    "        days=driver.find_element_by_css_selector('#content > section > div.area_list_search > div:nth-child({}) > div > div.info_post > div.writer_info > span.date'.format(j)).text\n",
    "        day.append(days)\n",
    "                       \n",
    "        \n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")\n",
    "\n",
    "result=[]\n",
    "\n",
    "for url in tqdm(url_list): # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    " \n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    overlays = \".se-component.se-text.se-l-default\" # 내용 크롤링\n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    driver.implicitly_wait(1)\n",
    " \n",
    "    for content in contents:\n",
    "        content_list = content_list+content.text # content_list 라는 값에 + 하면서 점점 누적\n",
    "    \n",
    "    result.append(content_list)\n",
    "    content_list=''    \n",
    "\n",
    "    \n",
    "## result라는 최종 데이터 프레임 생성\n",
    "result=pd.DataFrame(result, columns = ['리뷰']) #리뷰로 먼저 만들고\n",
    "result['url']=url_list # url 새로운 열로 추가\n",
    "result['title']=title\n",
    "result['name']=name\n",
    "result['day']=day\n",
    "result = result[['name','day','url','title','리뷰']]\n",
    "result.to_excel('전기차 후기(18년).xlsx')\n",
    "\n",
    "print(\"크롤링도 끝\")\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
